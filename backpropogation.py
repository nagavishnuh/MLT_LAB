# -*- coding: utf-8 -*-
"""BackPropogation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fYFEkn_3tXrMX2JMmDErVostAu0unZPO
"""

from sklearn.datasets import load_iris
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

data = load_iris()
x = data.data
y = data.target

sc = StandardScaler()
x = sc.fit_transform(x)
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)

n = 1000
loss_cur = 999
model = MLPClassifier(hidden_layer_sizes=(4,3),activation = "logistic", solver = "sgd", learning_rate_init = 0.5, warm_start = True, max_iter = 1, verbose = True, random_state = 1)
for _ in range(n):
  model.fit(x_train, y_train)
  loss_prev = loss_cur
  loss_cur = model.loss_
  for i in model.coefs_:
    print(i, sep=" ")
  if loss_prev - loss_cur <= 0.0001:
    break

print("The accuracy of the model is: ",model.score(x_test, y_test))

print("The final weights are: ")
for i in model.coefs_:
  print(i, sep = " ")